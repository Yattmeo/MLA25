{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Directory containing the audio files\n",
    "# directory = 'Data/genres_original'\n",
    "# # Directory to save the MEL spectrogram images\n",
    "# output_directory = 'mel_spectrograms'\n",
    "\n",
    "# # Create the output directory if it doesn't exist\n",
    "# os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# # Iterate over all subdirectories and files in the directory\n",
    "# for root, dirs, files in os.walk(directory):\n",
    "#     for file in files:\n",
    "#         if file.endswith('.wav'):  # Assuming the audio files are in .wav format\n",
    "#             file_path = os.path.join(root, file)\n",
    "#             try:\n",
    "#                 # Load the audio file\n",
    "#                 y, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "#                 # Extract MEL spectrogram\n",
    "#                 mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "#                 # Convert to log scale (dB)\n",
    "#                 log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "                \n",
    "#                 # Plot the MEL spectrogram\n",
    "#                 plt.figure(figsize=(10, 4))\n",
    "#                 librosa.display.specshow(log_mel_spectrogram, sr=sr, x_axis='time', y_axis='mel')\n",
    "#                 plt.colorbar(format='%+2.0f dB')\n",
    "#                 plt.title('MEL Spectrogram')\n",
    "#                 plt.tight_layout()\n",
    "                \n",
    "#                 # Save the plot as a PNG file\n",
    "#                 output_file_path = os.path.join(output_directory, f\"{os.path.splitext(file)[0]}.png\")\n",
    "#                 plt.savefig(output_file_path)\n",
    "#                 plt.close()\n",
    "                \n",
    "#                 print(f\"Saved MEL spectrogram for {file_path} as {output_file_path}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the MEL spectrogram images\n",
    "directory = 'mel_spectrograms'\n",
    "\n",
    "# List to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith('.png'):  # Assuming the spectrograms are in .png format\n",
    "        file_path = os.path.join(directory, file)\n",
    "        # Extract the genre from the filename (word before the first '.')\n",
    "        genre = file.split('.')[0]\n",
    "        # Append the data (filename, genre, file path) to the list\n",
    "        data.append([file, genre, file_path])\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "columns = ['filename', 'genre', 'spectrogram']\n",
    "df_ms = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df_ms.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "print(df_ms.head())\n",
    "\n",
    "# Display basic statistics\n",
    "print(df_ms.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(df_ms.isnull().sum())\n",
    "\n",
    "# Plot the distribution of genres\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_ms['genre'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Genres')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution of spectrogram file sizes\n",
    "file_sizes = df_ms['spectrogram'].apply(lambda x: os.path.getsize(x))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(file_sizes, bins=30, edgecolor='k')\n",
    "plt.title('Distribution of Spectrogram File Sizes')\n",
    "plt.xlabel('File Size (bytes)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tqdm import tqdm\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over the DataFrame rows\n",
    "for index, row in tqdm(df_ms.iterrows(), total=df_ms.shape[0]):\n",
    "    # Load the image\n",
    "    img = Image.open(row['spectrogram'])\n",
    "    # Convert the image to a numpy array\n",
    "    img_array = np.array(img)\n",
    "    # Append the image array to the features list\n",
    "    features.append(img_array)\n",
    "    # Append the genre (label) to the labels list\n",
    "    labels.append(row['genre'])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Print the shapes of the arrays\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "features = features / 255.0\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "unique_labels = np.unique(labels)\n",
    "label_to_index = {label: index for index, label in enumerate(unique_labels)}\n",
    "labels = np.array([label_to_index[label] for label in labels])\n",
    "labels = to_categorical(labels, num_classes=len(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(features.shape[1], features.shape[2], features.shape[3])),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(unique_labels), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ImageDataGenerator to load data in batches and perform data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Use a portion of the data for validation\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df_ms,\n",
    "    directory='mel_spectrograms',\n",
    "    x_col='spectrogram',\n",
    "    y_col='genre',\n",
    "    target_size=(features.shape[1], features.shape[2]),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df_ms,\n",
    "    directory='mel_spectrograms',\n",
    "    x_col='spectrogram',\n",
    "    y_col='genre',\n",
    "    target_size=(features.shape[1], features.shape[2]),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with detailed feedback\n",
    "model.fit(train_generator, epochs=10, validation_data=validation_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
